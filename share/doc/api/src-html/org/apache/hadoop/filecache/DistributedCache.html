<HTML>
<BODY BGCOLOR="white">
<PRE>
<FONT color="green">001</FONT>    /**<a name="line.1"></a>
<FONT color="green">002</FONT>     * Licensed to the Apache Software Foundation (ASF) under one<a name="line.2"></a>
<FONT color="green">003</FONT>     * or more contributor license agreements.  See the NOTICE file<a name="line.3"></a>
<FONT color="green">004</FONT>     * distributed with this work for additional information<a name="line.4"></a>
<FONT color="green">005</FONT>     * regarding copyright ownership.  The ASF licenses this file<a name="line.5"></a>
<FONT color="green">006</FONT>     * to you under the Apache License, Version 2.0 (the<a name="line.6"></a>
<FONT color="green">007</FONT>     * "License"); you may not use this file except in compliance<a name="line.7"></a>
<FONT color="green">008</FONT>     * with the License.  You may obtain a copy of the License at<a name="line.8"></a>
<FONT color="green">009</FONT>     *<a name="line.9"></a>
<FONT color="green">010</FONT>     *     http://www.apache.org/licenses/LICENSE-2.0<a name="line.10"></a>
<FONT color="green">011</FONT>     *<a name="line.11"></a>
<FONT color="green">012</FONT>     * Unless required by applicable law or agreed to in writing, software<a name="line.12"></a>
<FONT color="green">013</FONT>     * distributed under the License is distributed on an "AS IS" BASIS,<a name="line.13"></a>
<FONT color="green">014</FONT>     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<a name="line.14"></a>
<FONT color="green">015</FONT>     * See the License for the specific language governing permissions and<a name="line.15"></a>
<FONT color="green">016</FONT>     * limitations under the License.<a name="line.16"></a>
<FONT color="green">017</FONT>     */<a name="line.17"></a>
<FONT color="green">018</FONT>    <a name="line.18"></a>
<FONT color="green">019</FONT>    package org.apache.hadoop.filecache;<a name="line.19"></a>
<FONT color="green">020</FONT>    <a name="line.20"></a>
<FONT color="green">021</FONT>    import org.apache.hadoop.classification.InterfaceAudience;<a name="line.21"></a>
<FONT color="green">022</FONT>    import org.apache.hadoop.classification.InterfaceStability;<a name="line.22"></a>
<FONT color="green">023</FONT>    import org.apache.hadoop.conf.Configuration;<a name="line.23"></a>
<FONT color="green">024</FONT>    import org.apache.hadoop.fs.FileSystem;<a name="line.24"></a>
<FONT color="green">025</FONT>    import org.apache.hadoop.fs.Path;<a name="line.25"></a>
<FONT color="green">026</FONT>    import org.apache.hadoop.mapreduce.Job;<a name="line.26"></a>
<FONT color="green">027</FONT>    <a name="line.27"></a>
<FONT color="green">028</FONT>    /**<a name="line.28"></a>
<FONT color="green">029</FONT>     * Distribute application-specific large, read-only files efficiently.<a name="line.29"></a>
<FONT color="green">030</FONT>     * <a name="line.30"></a>
<FONT color="green">031</FONT>     * &lt;p&gt;&lt;code&gt;DistributedCache&lt;/code&gt; is a facility provided by the Map-Reduce<a name="line.31"></a>
<FONT color="green">032</FONT>     * framework to cache files (text, archives, jars etc.) needed by applications.<a name="line.32"></a>
<FONT color="green">033</FONT>     * &lt;/p&gt;<a name="line.33"></a>
<FONT color="green">034</FONT>     * <a name="line.34"></a>
<FONT color="green">035</FONT>     * &lt;p&gt;Applications specify the files, via urls (hdfs:// or http://) to be cached <a name="line.35"></a>
<FONT color="green">036</FONT>     * via the {@link org.apache.hadoop.mapred.JobConf}. The<a name="line.36"></a>
<FONT color="green">037</FONT>     * &lt;code&gt;DistributedCache&lt;/code&gt; assumes that the files specified via urls are<a name="line.37"></a>
<FONT color="green">038</FONT>     * already present on the {@link FileSystem} at the path specified by the url<a name="line.38"></a>
<FONT color="green">039</FONT>     * and are accessible by every machine in the cluster.&lt;/p&gt;<a name="line.39"></a>
<FONT color="green">040</FONT>     * <a name="line.40"></a>
<FONT color="green">041</FONT>     * &lt;p&gt;The framework will copy the necessary files on to the slave node before <a name="line.41"></a>
<FONT color="green">042</FONT>     * any tasks for the job are executed on that node. Its efficiency stems from <a name="line.42"></a>
<FONT color="green">043</FONT>     * the fact that the files are only copied once per job and the ability to <a name="line.43"></a>
<FONT color="green">044</FONT>     * cache archives which are un-archived on the slaves.&lt;/p&gt; <a name="line.44"></a>
<FONT color="green">045</FONT>     *<a name="line.45"></a>
<FONT color="green">046</FONT>     * &lt;p&gt;&lt;code&gt;DistributedCache&lt;/code&gt; can be used to distribute simple, read-only<a name="line.46"></a>
<FONT color="green">047</FONT>     * data/text files and/or more complex types such as archives, jars etc. <a name="line.47"></a>
<FONT color="green">048</FONT>     * Archives (zip, tar and tgz/tar.gz files) are un-archived at the slave nodes. <a name="line.48"></a>
<FONT color="green">049</FONT>     * Jars may be optionally added to the classpath of the tasks, a rudimentary <a name="line.49"></a>
<FONT color="green">050</FONT>     * software distribution mechanism.  Files have execution permissions.<a name="line.50"></a>
<FONT color="green">051</FONT>     * In older version of Hadoop Map/Reduce users could optionally ask for symlinks<a name="line.51"></a>
<FONT color="green">052</FONT>     * to be created in the working directory of the child task.  In the current <a name="line.52"></a>
<FONT color="green">053</FONT>     * version symlinks are always created.  If the URL does not have a fragment <a name="line.53"></a>
<FONT color="green">054</FONT>     * the name of the file or directory will be used. If multiple files or <a name="line.54"></a>
<FONT color="green">055</FONT>     * directories map to the same link name, the last one added, will be used.  All<a name="line.55"></a>
<FONT color="green">056</FONT>     * others will not even be downloaded.&lt;/p&gt;<a name="line.56"></a>
<FONT color="green">057</FONT>     * <a name="line.57"></a>
<FONT color="green">058</FONT>     * &lt;p&gt;&lt;code&gt;DistributedCache&lt;/code&gt; tracks modification timestamps of the cache <a name="line.58"></a>
<FONT color="green">059</FONT>     * files. Clearly the cache files should not be modified by the application <a name="line.59"></a>
<FONT color="green">060</FONT>     * or externally while the job is executing.&lt;/p&gt;<a name="line.60"></a>
<FONT color="green">061</FONT>     * <a name="line.61"></a>
<FONT color="green">062</FONT>     * &lt;p&gt;Here is an illustrative example on how to use the <a name="line.62"></a>
<FONT color="green">063</FONT>     * &lt;code&gt;DistributedCache&lt;/code&gt;:&lt;/p&gt;<a name="line.63"></a>
<FONT color="green">064</FONT>     * &lt;p&gt;&lt;blockquote&gt;&lt;pre&gt;<a name="line.64"></a>
<FONT color="green">065</FONT>     *     // Setting up the cache for the application<a name="line.65"></a>
<FONT color="green">066</FONT>     *     <a name="line.66"></a>
<FONT color="green">067</FONT>     *     1. Copy the requisite files to the &lt;code&gt;FileSystem&lt;/code&gt;:<a name="line.67"></a>
<FONT color="green">068</FONT>     *     <a name="line.68"></a>
<FONT color="green">069</FONT>     *     $ bin/hadoop fs -copyFromLocal lookup.dat /myapp/lookup.dat  <a name="line.69"></a>
<FONT color="green">070</FONT>     *     $ bin/hadoop fs -copyFromLocal map.zip /myapp/map.zip  <a name="line.70"></a>
<FONT color="green">071</FONT>     *     $ bin/hadoop fs -copyFromLocal mylib.jar /myapp/mylib.jar<a name="line.71"></a>
<FONT color="green">072</FONT>     *     $ bin/hadoop fs -copyFromLocal mytar.tar /myapp/mytar.tar<a name="line.72"></a>
<FONT color="green">073</FONT>     *     $ bin/hadoop fs -copyFromLocal mytgz.tgz /myapp/mytgz.tgz<a name="line.73"></a>
<FONT color="green">074</FONT>     *     $ bin/hadoop fs -copyFromLocal mytargz.tar.gz /myapp/mytargz.tar.gz<a name="line.74"></a>
<FONT color="green">075</FONT>     *     <a name="line.75"></a>
<FONT color="green">076</FONT>     *     2. Setup the application's &lt;code&gt;JobConf&lt;/code&gt;:<a name="line.76"></a>
<FONT color="green">077</FONT>     *     <a name="line.77"></a>
<FONT color="green">078</FONT>     *     JobConf job = new JobConf();<a name="line.78"></a>
<FONT color="green">079</FONT>     *     DistributedCache.addCacheFile(new URI("/myapp/lookup.dat#lookup.dat"), <a name="line.79"></a>
<FONT color="green">080</FONT>     *                                   job);<a name="line.80"></a>
<FONT color="green">081</FONT>     *     DistributedCache.addCacheArchive(new URI("/myapp/map.zip", job);<a name="line.81"></a>
<FONT color="green">082</FONT>     *     DistributedCache.addFileToClassPath(new Path("/myapp/mylib.jar"), job);<a name="line.82"></a>
<FONT color="green">083</FONT>     *     DistributedCache.addCacheArchive(new URI("/myapp/mytar.tar", job);<a name="line.83"></a>
<FONT color="green">084</FONT>     *     DistributedCache.addCacheArchive(new URI("/myapp/mytgz.tgz", job);<a name="line.84"></a>
<FONT color="green">085</FONT>     *     DistributedCache.addCacheArchive(new URI("/myapp/mytargz.tar.gz", job);<a name="line.85"></a>
<FONT color="green">086</FONT>     *     <a name="line.86"></a>
<FONT color="green">087</FONT>     *     3. Use the cached files in the {@link org.apache.hadoop.mapred.Mapper}<a name="line.87"></a>
<FONT color="green">088</FONT>     *     or {@link org.apache.hadoop.mapred.Reducer}:<a name="line.88"></a>
<FONT color="green">089</FONT>     *     <a name="line.89"></a>
<FONT color="green">090</FONT>     *     public static class MapClass extends MapReduceBase  <a name="line.90"></a>
<FONT color="green">091</FONT>     *     implements Mapper&amp;lt;K, V, K, V&amp;gt; {<a name="line.91"></a>
<FONT color="green">092</FONT>     *     <a name="line.92"></a>
<FONT color="green">093</FONT>     *       private Path[] localArchives;<a name="line.93"></a>
<FONT color="green">094</FONT>     *       private Path[] localFiles;<a name="line.94"></a>
<FONT color="green">095</FONT>     *       <a name="line.95"></a>
<FONT color="green">096</FONT>     *       public void configure(JobConf job) {<a name="line.96"></a>
<FONT color="green">097</FONT>     *         // Get the cached archives/files<a name="line.97"></a>
<FONT color="green">098</FONT>     *         File f = new File("./map.zip/some/file/in/zip.txt");<a name="line.98"></a>
<FONT color="green">099</FONT>     *       }<a name="line.99"></a>
<FONT color="green">100</FONT>     *       <a name="line.100"></a>
<FONT color="green">101</FONT>     *       public void map(K key, V value, <a name="line.101"></a>
<FONT color="green">102</FONT>     *                       OutputCollector&amp;lt;K, V&amp;gt; output, Reporter reporter) <a name="line.102"></a>
<FONT color="green">103</FONT>     *       throws IOException {<a name="line.103"></a>
<FONT color="green">104</FONT>     *         // Use data from the cached archives/files here<a name="line.104"></a>
<FONT color="green">105</FONT>     *         // ...<a name="line.105"></a>
<FONT color="green">106</FONT>     *         // ...<a name="line.106"></a>
<FONT color="green">107</FONT>     *         output.collect(k, v);<a name="line.107"></a>
<FONT color="green">108</FONT>     *       }<a name="line.108"></a>
<FONT color="green">109</FONT>     *     }<a name="line.109"></a>
<FONT color="green">110</FONT>     *     <a name="line.110"></a>
<FONT color="green">111</FONT>     * &lt;/pre&gt;&lt;/blockquote&gt;&lt;/p&gt;<a name="line.111"></a>
<FONT color="green">112</FONT>     *<a name="line.112"></a>
<FONT color="green">113</FONT>     * It is also very common to use the DistributedCache by using<a name="line.113"></a>
<FONT color="green">114</FONT>     * {@link org.apache.hadoop.util.GenericOptionsParser}.<a name="line.114"></a>
<FONT color="green">115</FONT>     *<a name="line.115"></a>
<FONT color="green">116</FONT>     * This class includes methods that should be used by users<a name="line.116"></a>
<FONT color="green">117</FONT>     * (specifically those mentioned in the example above, as well<a name="line.117"></a>
<FONT color="green">118</FONT>     * as {@link DistributedCache#addArchiveToClassPath(Path, Configuration)}),<a name="line.118"></a>
<FONT color="green">119</FONT>     * as well as methods intended for use by the MapReduce framework<a name="line.119"></a>
<FONT color="green">120</FONT>     * (e.g., {@link org.apache.hadoop.mapred.JobClient}).<a name="line.120"></a>
<FONT color="green">121</FONT>     *<a name="line.121"></a>
<FONT color="green">122</FONT>     * @see org.apache.hadoop.mapred.JobConf<a name="line.122"></a>
<FONT color="green">123</FONT>     * @see org.apache.hadoop.mapred.JobClient<a name="line.123"></a>
<FONT color="green">124</FONT>     * @see org.apache.hadoop.mapreduce.Job<a name="line.124"></a>
<FONT color="green">125</FONT>     */<a name="line.125"></a>
<FONT color="green">126</FONT>    @InterfaceAudience.Public<a name="line.126"></a>
<FONT color="green">127</FONT>    @InterfaceStability.Stable<a name="line.127"></a>
<FONT color="green">128</FONT>    public class DistributedCache extends<a name="line.128"></a>
<FONT color="green">129</FONT>        org.apache.hadoop.mapreduce.filecache.DistributedCache {<a name="line.129"></a>
<FONT color="green">130</FONT>      //<a name="line.130"></a>
<FONT color="green">131</FONT>    }<a name="line.131"></a>




























































</PRE>
</BODY>
</HTML>
